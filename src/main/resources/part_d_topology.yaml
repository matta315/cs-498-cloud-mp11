# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---

# topology definition
# name to be used when submitting
name: "part-D"

# TODO
# Task: implement your topology for part d

# topology configuration
# this will be passed to the submitter as a map of config options
config:
    storm.local.hostname: "localhost"
    topology.max.task.parallelism: 12
    # set this to true if you want to see more debug log
    # set it to false before submitting
    topology.debug: false
    # Hint: you can set input file path here
    # make sure it's "/tmp/data.txt" in your final submission
    input_file: "/tmp/data.txt"

    # Hint: set N here
    # make sure it's 10 in your final submission
    N: 10

components:
  - id: "poolConfig"
    className: "org.apache.storm.redis.common.config.JedisPoolConfig"
    constructorArgs:
      - "localhost"
      - 6379
      - 2000
      - "uiuc_cs498_mp7"
      - 0

  # TODO
  # Task: implement the redis store mapper
  # src/main/java/edu/illinois/storm/TopNStoreMapper.java
  # redis hash key for part D is "partDTopN"
  - id: "topNStoreMapper"
    className: "edu.illinois.storm.TopNStoreMapper"
    constructorArgs:
      - "partDTopN"

# spout definitions
spouts:
  - id: "file-reader"
    className: "org.apache.storm.flux.wrappers.spouts.FluxShellSpout"
    constructorArgs:
      # Command line
      - ["python", "file_reader_spout.py"]
      # Output field(s)
      - ["sentence"]
      # parallelism hint
    parallelism: 1
  # multilang/resources/random_sentence_spout.py
  # Hint: you need to define output field(s) here when using FluxShellSpout
  # Hint: the new file reading spout you need implement in this part is
  # multilang/resources/file_reader_spout.py

# bolt definitions
bolts:
  # TODO
  # Task: implement the split sentences bolt
  # multilang/resources/split_sentence_bolt.py
  - id: "splitter-bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      # Command line
      - ["python", "split_sentence_bolt.py"]
      # Output field(s)
      - ["word"]
    parallelism: 12

  - id: "norm-bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      # Command line
      - ["python", "normalizer_bolt.py"]
      # Output field(s)
      - ["word"]
    parallelism: 12

  # TODO
  # Task: implement the word count bolt
  # multilang/resources/word_count_bolt.py
  - id: "counter-bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      # Command line
      - ["python", "word_count_bolt.py"]
      # Output field(s)
      - ["word","count"]
    parallelism: 12

  - id: "topn-bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      # Command line
      - ["python", "top_n_finder_bolt.py"]
      # Output field(s)
      - ["top_n","top_n_words"]
    parallelism: 1

  # TODO
  # Task: initialize RedisStoreBolt using poolConfig and storeMapper
  # ClassName is "org.apache.storm.redis.bolt.RedisStoreBolt"
  - id: "redis-cache"
    className: "org.apache.storm.redis.bolt.RedisStoreBolt"
    constructorArgs:
      - ref: "poolConfig"
      - ref: "topNStoreMapper"
    parallelism: 12

# stream definitions
# stream definitions define connections between spouts and bolts.
streams:
  # TODO
  # Task: pipe output of sentences generating spout to split bolt
  - name: "file-reader --> Splitter" # name isn't used (placeholder for logging, UI, etc.)
    # The stream emitter
    from: "file-reader"
    # The stream consumer
    to: "splitter-bolt"
    # Grouping type
    grouping:
      type: SHUFFLE

  # TODO
  # Task: pipe output of split bolt to word count bolt
  # Hint: choose the right grouping type to make problem easier

  - name: "Splitter -> Norm"
    from: "splitter-bolt"
    to: "norm-bolt"
    grouping:
      type: SHUFFLE

  - name: "Norm -> Counter"
    from: "norm-bolt"
    to: "counter-bolt"
    grouping:
      type: FIELDS
      # field(s) to group on
      args: ["word"]

  - name: "Counter -> Top N Finder"
    from: "counter-bolt"
    to: "topn-bolt"
    grouping:
      type: SHUFFLE

  # TODO
  # Task: pipe output of top N word count bolt to redis store bolt
  - name: "Top N Finder -> redis-cache"
    from: "topn-bolt"
    to: "redis-cache"
    grouping:
      type: SHUFFLE
